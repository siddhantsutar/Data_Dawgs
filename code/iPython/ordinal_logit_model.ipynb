{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Siddhant Sutar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas, Numpy, and ordered logistic regression module by Fabian Pedregosa (with a few tweaks) obtained from https://github.com/fabianp/minirank/blob/master/minirank/logistic.py, since Scikit-learn doesn't support it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from logistic import ordinal_logistic_fit, ordinal_logistic_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import NLTK library and TfIdfVectorizer to handle plot data. Vectorize the plot keywords and store in a sparse CSR matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopset = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(use_idf=False, norm=False, strip_accents='ascii', stop_words=stopset, binary=True)\n",
    "train[\"FullPlot\"] = train[\"FullPlot\"].fillna('')\n",
    "plot_keywords = vectorizer.fit_transform(train.FullPlot)\n",
    "keywords_list = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50184x60376 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1325307 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read feature vectors into a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "genres = pd.read_csv(\"genres.csv\")\n",
    "directors = pd.read_csv(\"directors.csv\", usecols=['Row', 'Column'])\n",
    "actors = pd.read_csv(\"actors.csv\", usecols=['Row', 'Column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of unique actors and directors present in the sparse COO feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actors_list = pd.unique(actors[\"Column\"].values.ravel()).tolist()\n",
    "directors_list = pd.unique(directors[\"Column\"].values.ravel()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate feature column with 1s and 0s for an actor/director predictor into a readable format (Pandas) for the linear regression model, since they are stored as sparse COO matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_col(df, name, prefix=''):\n",
    "    fc = pd.DataFrame(train[\"ID\"], columns=['ID'], dtype=np.int64)\n",
    "    fc[name] = 0\n",
    "    temp = df.loc[df['Column'].isin([name])]\n",
    "    fc.ix[fc.ID.isin(temp.Row.tolist()), name] = 1\n",
    "    fc = fc.rename(columns = {name : prefix + name})\n",
    "    return fc[prefix + name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordered logit regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_minimize.py:366: RuntimeWarning: Method TNC does not use Hessian-vector product information (hessp).\n",
      "  'information (hessp).' % method, RuntimeWarning)\n",
      "logistic.py:226: OptimizeWarning: Unknown solver options: maxfun\n",
      "  jac=f_grad, hessp=f_hess, options=options, callback=callback)\n"
     ]
    }
   ],
   "source": [
    "g = ['Action', 'Adventure', 'Sci-Fi']\n",
    "d = ['Tim Miller']\n",
    "c = ['Morena Baccarin', 'Ryan Reynolds', 'Gina Carano', 'Ed Skrein']\n",
    "keywords = [] #[\"corruption\", \"government\", \"girl\"]\n",
    "feature_cols = [genres[g]]\n",
    "for each in d:\n",
    "    feature_cols.append(get_feature_col(directors, each, 'dir_'))\n",
    "for each in c:\n",
    "    feature_cols.append(get_feature_col(actors, each))\n",
    "for each in keywords:\n",
    "    if each in keywords_list:\n",
    "        feature_cols.append(pd.DataFrame(plot_keywords[:, keywords_list.index(each)].toarray().flatten(), columns=[each]))\n",
    "X = pd.concat([each for each in feature_cols], axis=1)\n",
    "y = train.OrderedRating\n",
    "w, theta = ordinal_logistic_fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordered ratings: 0 = [0-5), 1 = [5-6), 2 = [6-7), 3 = [7-8), 4 = [8-9), 5 = [9-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "pred = ordinal_logistic_predict(w, theta, np.ones(len(X.columns)))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20600\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "predicted_dict = json.load(open(\"predicted_logistic.json\", \"r\"))\n",
    "y = train.OrderedRating\n",
    "print len(predicted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "    if row[\"Title\"] not in predicted_dict:\n",
    "        feature_cols = []\n",
    "        my_genres = row[\"Genre\"].split(\", \")\n",
    "        for each in my_genres:\n",
    "            feature_cols.append(genres[each])\n",
    "        if pd.notnull(row[\"Director\"]):\n",
    "            my_directors = row[\"Director\"].split(\", \")\n",
    "            for each in my_directors:\n",
    "                if each in directors_list:\n",
    "                    feature_cols.append(get_feature_col(directors, each, 'dir_'))\n",
    "        if pd.notnull(row[\"Cast\"]):            \n",
    "            my_actors = row[\"Cast\"].split(\", \")\n",
    "            for each in my_actors:\n",
    "                if each in actors_list:\n",
    "                    feature_cols.append(get_feature_col(actors, each))\n",
    "        X = pd.concat([each for each in feature_cols], axis=1)\n",
    "        w, theta = ordinal_logistic_fit(X, y)\n",
    "        predicted_dict[row[\"Title\"]] = int(ordinal_logistic_predict(w, theta, np.ones(len(X.columns))))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('predicted_logistic.json', 'w') as outfile:\n",
    "    json.dump(predicted_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
